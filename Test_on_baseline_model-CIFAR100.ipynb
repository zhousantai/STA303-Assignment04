{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 01: Multi-class Classification \n",
    "In this Assignment, you will train a deep model on the CIFAR10 from the scratch using PyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-13T05:28:24.670314Z",
     "iopub.status.busy": "2024-01-13T05:28:24.670000Z",
     "iopub.status.idle": "2024-01-13T05:28:26.392722Z",
     "shell.execute_reply": "2024-01-13T05:28:26.391994Z",
     "shell.execute_reply.started": "2024-01-13T05:28:24.670274Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "import os\n",
    "import time\n",
    "import os.path as osp\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-13T05:28:26.394436Z",
     "iopub.status.busy": "2024-01-13T05:28:26.394154Z",
     "iopub.status.idle": "2024-01-13T05:28:26.397715Z",
     "shell.execute_reply": "2024-01-13T05:28:26.397279Z",
     "shell.execute_reply.started": "2024-01-13T05:28:26.394413Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# random seed\n",
    "SEED = 1 \n",
    "NUM_CLASS = 100\n",
    "\n",
    "# Training\n",
    "BATCH_SIZE = 64\n",
    "NUM_EPOCHS = 60\n",
    "EVAL_INTERVAL=1\n",
    "SAVE_DIR = './log'\n",
    "\n",
    "# Optimizer\n",
    "LEARNING_RATE = 1e-3\n",
    "MOMENTUM = 0.9\n",
    "STEP=5\n",
    "GAMMA=0.5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-13T05:28:26.398435Z",
     "iopub.status.busy": "2024-01-13T05:28:26.398288Z",
     "iopub.status.idle": "2024-01-13T05:28:26.483787Z",
     "shell.execute_reply": "2024-01-13T05:28:26.483198Z",
     "shell.execute_reply.started": "2024-01-13T05:28:26.398419Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device=\"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-13T05:28:26.484665Z",
     "iopub.status.busy": "2024-01-13T05:28:26.484485Z",
     "iopub.status.idle": "2024-01-13T05:29:20.369648Z",
     "shell.execute_reply": "2024-01-13T05:29:20.368796Z",
     "shell.execute_reply.started": "2024-01-13T05:28:26.484648Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to ../data/cifar-100-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 169001437/169001437 [00:49<00:00, 3447349.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/cifar-100-python.tar.gz to ../data\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform_cifar100_train = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761)),\n",
    "])\n",
    "\n",
    "transform_cifar100_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761)),\n",
    "])\n",
    "\n",
    "train_set = torchvision.datasets.CIFAR100(root='../data', train=True,\n",
    "                                        download=True, transform=transform_cifar100_train)\n",
    "train_dataloader = torch.utils.data.DataLoader(train_set, batch_size=BATCH_SIZE,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "test_set = torchvision.datasets.CIFAR100(root='../data', train=False,\n",
    "                                       download=True, transform=transform_cifar100_test)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_set, batch_size=BATCH_SIZE,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "class_names = train_set.classes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-13T05:29:20.370662Z",
     "iopub.status.busy": "2024-01-13T05:29:20.370482Z",
     "iopub.status.idle": "2024-01-13T05:29:20.377131Z",
     "shell.execute_reply": "2024-01-13T05:29:20.376704Z",
     "shell.execute_reply.started": "2024-01-13T05:29:20.370642Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        \n",
    "        self.fc1 = nn.Linear(64 * 4 * 4, 256)\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        \n",
    "        self.fc2 = nn.Linear(256, 100)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu1(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(self.relu2(self.bn2(self.conv2(x))))\n",
    "        x = self.pool(self.relu3(self.bn3(self.conv3(x))))\n",
    "        \n",
    "        x = x.view(-1, 64 * 4 * 4)\n",
    "        \n",
    "        x = self.relu4(self.dropout1(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-13T05:29:20.378016Z",
     "iopub.status.busy": "2024-01-13T05:29:20.377703Z",
     "iopub.status.idle": "2024-01-13T05:29:20.612074Z",
     "shell.execute_reply": "2024-01-13T05:29:20.611573Z",
     "shell.execute_reply.started": "2024-01-13T05:29:20.377998Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvNet(\n",
       "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu1): ReLU()\n",
       "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu2): ReLU()\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu3): ReLU()\n",
       "  (fc1): Linear(in_features=1024, out_features=256, bias=True)\n",
       "  (dropout1): Dropout(p=0.5, inplace=False)\n",
       "  (relu4): ReLU()\n",
       "  (fc2): Linear(in_features=256, out_features=100, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=ConvNet()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-13T05:29:20.615236Z",
     "iopub.status.busy": "2024-01-13T05:29:20.615080Z",
     "iopub.status.idle": "2024-01-13T05:29:20.618427Z",
     "shell.execute_reply": "2024-01-13T05:29:20.618044Z",
     "shell.execute_reply.started": "2024-01-13T05:29:20.615220Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=MOMENTUM)\n",
    "from torch.optim import lr_scheduler\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=STEP, gamma=GAMMA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: per batch training/testing\n",
    "---\n",
    "\n",
    "Please denfine two function named ``train_batch`` and ``test_batch``. These functions are essential for training and evaluating machine learning models using batched data from dataloaders.\n",
    "\n",
    "**To do**: \n",
    "1. Define the loss function i.e [nn.CrossEntropyLoss()](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html).\n",
    "2. Take the image as the input and generate the output using the pre-defined SimpleNet.\n",
    "3. Calculate the loss between the output and the corresponding label using the loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-13T05:29:20.619289Z",
     "iopub.status.busy": "2024-01-13T05:29:20.618923Z",
     "iopub.status.idle": "2024-01-13T05:29:20.622456Z",
     "shell.execute_reply": "2024-01-13T05:29:20.622093Z",
     "shell.execute_reply.started": "2024-01-13T05:29:20.619273Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_batch(model, image, target):\n",
    "    \"\"\"\n",
    "    Perform one training batch iteration.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The machine learning model to train.\n",
    "        image (torch.Tensor): Batch of input data (images).\n",
    "        target (torch.Tensor): Batch of target labels.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Model output (predictions) for the batch.\n",
    "        torch.Tensor: Loss value calculated by the defined loss function loss_fn().\n",
    "    \"\"\"\n",
    "    \n",
    "    ##################### Write your answer here ##################\n",
    "\n",
    "    output = model(image)\n",
    "    loss = criterion(output, target)\n",
    "\n",
    "    ###############################################################\n",
    "\n",
    "    return output, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-13T05:29:20.623065Z",
     "iopub.status.busy": "2024-01-13T05:29:20.622926Z",
     "iopub.status.idle": "2024-01-13T05:29:20.627501Z",
     "shell.execute_reply": "2024-01-13T05:29:20.627127Z",
     "shell.execute_reply.started": "2024-01-13T05:29:20.623050Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "##################### Write your answer here ##################\n",
    "# Define the loss function\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=2.0, alpha=1.0):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        \"\"\"\n",
    "        y_pred: raw scores (logits) for each class. [batch_size, num_classes]\n",
    "        y_true: ground truth labels. [batch_size]\n",
    "        \"\"\"\n",
    "        # Convert y_true labels into one-hot encoding\n",
    "        y_true_onehot = torch.zeros(y_pred.size(), device=y_pred.device).scatter_(1, y_true.unsqueeze(1).long(), 1)\n",
    "        \n",
    "        # Calculate softmax over y_pred for calculating probabilities\n",
    "        probs = F.softmax(y_pred, dim=1)\n",
    "        \n",
    "        # Calculate focal loss\n",
    "        focal_loss = -self.alpha * (y_true_onehot * torch.log(probs) * (1 - probs) ** self.gamma).sum(dim=1).mean()\n",
    "        \n",
    "        return focal_loss\n",
    "\n",
    "\n",
    "#criterion = nn.L1Loss()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#criterion = FocalLoss(gamma=0.5)\n",
    "#criterion = FocalLoss(gamma=2.0)\n",
    "\n",
    "def one_hot_encoding(target, num_classes):\n",
    "    return F.one_hot(target, num_classes=num_classes).float()\n",
    "\n",
    "\n",
    "###############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-13T05:29:20.628182Z",
     "iopub.status.busy": "2024-01-13T05:29:20.628041Z",
     "iopub.status.idle": "2024-01-13T05:29:20.630897Z",
     "shell.execute_reply": "2024-01-13T05:29:20.630534Z",
     "shell.execute_reply.started": "2024-01-13T05:29:20.628167Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def test_batch(model, image, target):\n",
    "    \"\"\"\n",
    "    Perform one testing batch iteration.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The machine learning model to evaluate.\n",
    "        image (torch.Tensor): Batch of input data (images).\n",
    "        target (torch.Tensor): Batch of target labels.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Model output (predictions) for the batch.\n",
    "        torch.Tensor: Loss value calculated for the batch.\n",
    "    \"\"\"\n",
    "\n",
    "    ##################### Write your answer here ##################\n",
    "   # model.eval()\n",
    "   # with torch.no_grad():\n",
    "    output = model(image)\n",
    "    loss = criterion(output, target)\n",
    "        \n",
    "        \n",
    "    ###############################################################\n",
    "\n",
    "    return output, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-13T05:29:20.631546Z",
     "iopub.status.busy": "2024-01-13T05:29:20.631408Z",
     "iopub.status.idle": "2024-01-13T05:29:20.637820Z",
     "shell.execute_reply": "2024-01-13T05:29:20.637455Z",
     "shell.execute_reply.started": "2024-01-13T05:29:20.631531Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# training_loss = []\n",
    "# training_acc = []\n",
    "# testing_loss = []\n",
    "# testing_acc = []\n",
    "# start_time = time.time()  # 记录开始时间\n",
    "# all_preds = []\n",
    "# all_targets = []\n",
    "# # 日志文件\n",
    "# log_file = 'training_log.txt'\n",
    "# for epoch in range(NUM_EPOCHS):\n",
    "#     model.train()\n",
    "#     torch.cuda.empty_cache()\n",
    "\n",
    "#     ##########################\n",
    "#     ### Training\n",
    "#     ##########################\n",
    "\n",
    "#     running_cls_loss = 0.0\n",
    "#     running_cls_corrects = 0\n",
    "\n",
    "#     for batch_idx, (image, target) in enumerate(train_dataloader):\n",
    "#         image = image.to(device)\n",
    "#         target = target.to(device)\n",
    " \n",
    "#         outputs, loss = train_batch(model, image, target)\n",
    "     \n",
    "#         _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        \n",
    "#         loss_data = loss.data.item()\n",
    "#         if np.isnan(loss_data):\n",
    "#             raise ValueError('loss is nan while training')\n",
    "#         running_cls_loss += loss.item()\n",
    "#         running_cls_corrects += torch.sum(preds == target.data)\n",
    "\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         optimizer.zero_grad()\n",
    "\n",
    "#     epoch_loss = running_cls_loss / len(train_set)\n",
    "#     epoch_acc = running_cls_corrects.double() / len(train_set)\n",
    "\n",
    "#     print(f'Epoch: {epoch+1}/{NUM_EPOCHS} Train Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "    \n",
    "#     #########\n",
    "#     all_preds.extend(preds.cpu().numpy())\n",
    "#     all_targets.extend(target.cpu().numpy())\n",
    "#     f1 = f1_score(all_targets, all_preds, average='weighted')\n",
    "#     print(f\"f1 score in {epoch}th epoch is {f1}\")\n",
    "\n",
    "# ############\n",
    "#     training_loss.append(epoch_loss)\n",
    "#     training_acc.append(epoch_acc.cpu().detach().numpy())\n",
    "\n",
    "#     # change learning rate\n",
    "#     scheduler.step()\n",
    "\n",
    "\n",
    "#     ##########################\n",
    "#     ### Testing\n",
    "#     ##########################\n",
    "#     # # eval model during training or in the last epoch\n",
    "    \n",
    "#     if (epoch + 1) % EVAL_INTERVAL == 0 or (epoch +1) == NUM_EPOCHS:\n",
    "#         print('Begin test......')\n",
    "#         model.eval()\n",
    "    \n",
    "#         val_loss = 0.0\n",
    "#         val_corrects = 0\n",
    "\n",
    "#         for batch_idx, (image, target) in enumerate(test_dataloader):\n",
    "\n",
    "#             image = image.to(device)\n",
    "#             target = target.to(device)\n",
    "\n",
    "#             # test model\n",
    "#             ##################\n",
    "#           #  target_one_hot = one_hot_encoding(target, 10)  # 转换成 one-hot 编码\n",
    "#             outputs, loss = test_batch(model, image, target)\n",
    "#           #  outputs, loss = test_batch(model, image, target_one_hot)  # 使用 one-hot 编码后的目标\n",
    "#             #######################\n",
    "#             _, preds = torch.max(outputs, 1)\n",
    "            \n",
    "#             val_loss += loss.item()\n",
    "#             val_corrects += torch.sum(preds == target.data)\n",
    "\n",
    "#         val_loss = val_loss / len(test_set)\n",
    "#         val_acc = val_corrects.double() / len(test_set)\n",
    "#         print(f'Test Loss: {val_loss:.4f} Acc: {val_acc:.4f}')\n",
    "#         testing_loss.append(val_loss)\n",
    "#         testing_acc.append(val_acc.cpu().detach().numpy())\n",
    "#     with open(log_file, 'a') as f:\n",
    "#         f.write(f'Epoch {epoch+1}/{NUM_EPOCHS}\\n')\n",
    "#         f.write(f'Train Accuracy: {epoch_acc:.4f}%\\n')\n",
    "#         f.write(f'Test Accuracy: {val_acc:.4f}%\\n')\n",
    "#         f.write('\\n')\n",
    "\n",
    "#         # save the model in last epoch\n",
    "#         if (epoch +1) == NUM_EPOCHS:\n",
    "            \n",
    "#             state = {\n",
    "#             'state_dict': model.state_dict(),\n",
    "#             'acc': epoch_acc,\n",
    "#             'epoch': (epoch+1),\n",
    "#             }\n",
    "\n",
    "#             # check the dir\n",
    "#             if not os.path.exists(SAVE_DIR):\n",
    "#                 os.makedirs(SAVE_DIR)\n",
    "\n",
    "#             # save the state\n",
    "#             torch.save(state, osp.join(SAVE_DIR, 'checkpoint_%s.pth' % (str(epoch+1))))\n",
    "            \n",
    "# end_time = time.time()  # 记录结束时间\n",
    "# duration = end_time - start_time  # 计算训练时间\n",
    "# print(f\"训练模型用时：{duration}秒\")\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Instance inference\n",
    "---\n",
    "The task is to visualizes an image along with model prediction and class probabilities.\n",
    "\n",
    "**To do**: \n",
    "1. Calculate the prediction and the probabilities for each class.\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-13T05:29:20.638434Z",
     "iopub.status.busy": "2024-01-13T05:29:20.638296Z",
     "iopub.status.idle": "2024-01-13T05:29:20.640848Z",
     "shell.execute_reply": "2024-01-13T05:29:20.640467Z",
     "shell.execute_reply.started": "2024-01-13T05:29:20.638419Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# inputs, classes = next(iter(test_dataloader))\n",
    "# input = inputs[0]\n",
    "# ##################### Write your answer here ##################\n",
    "# # input: image, model\n",
    "# # outputs: predict_label, probabilities\n",
    "# # predict_label is the index (or label) of the class with the highest probability from the probabilities.\n",
    "# ###############################################################\n",
    "# input_tensor = input.unsqueeze(0).to(device)\n",
    "# model.eval()\n",
    "# with torch.no_grad():\n",
    "#     output = model(input_tensor)\n",
    "#     probabilities = F.softmax(output, dim=1)\n",
    "#     predict_label = torch.argmax(probabilities)\n",
    "# # predict_label = \n",
    "# predicted_class = class_names[predict_label.item()]\n",
    "# predicted_probability = probabilities[0][predict_label.item()]\n",
    "# image = input.numpy().transpose((1, 2, 0))\n",
    "# plt.imshow(image)\n",
    "# plt.text(17, 30, f'Predicted Class: {predicted_class}\\nProbability: {predicted_probability:.2f}', \n",
    "#             color='white', backgroundcolor='black', fontsize=8)\n",
    "# plt.show()\n",
    "\n",
    "# # Print probabilities for each class\n",
    "# print('Print probabilities for each class:')\n",
    "# for i in range(len(class_names)):\n",
    "#     print(f'{class_names[i]}: {probabilities[0][i].item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-13T05:29:20.641534Z",
     "iopub.status.busy": "2024-01-13T05:29:20.641395Z",
     "iopub.status.idle": "2024-01-13T05:29:20.747520Z",
     "shell.execute_reply": "2024-01-13T05:29:20.747050Z",
     "shell.execute_reply.started": "2024-01-13T05:29:20.641518Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install torchcp\n",
    "# from torchcp.classification.scores import THR, APS, SAPS, RAPS\n",
    "# from torchcp.classification.predictors import SplitPredictor, ClusterPredictor, ClassWisePredictor\n",
    "\n",
    "\n",
    "# from torch.utils.data import DataLoader\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# log_name=\"CIFAR100\"\n",
    "# model=torch.load(\"CIFAR100model\")\n",
    "# results = []\n",
    "# alphas = [0.05, 0.1, 0.15, 0.2]\n",
    "# saps_weights = [0.5, 1, 1.5, 2]\n",
    "# raps_penalties = [0.05, 0.1, 0.15, 0.2]\n",
    "# raps_kregs = [0, 1, 2, 5]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# alpha=0.1\n",
    "# weight=1\n",
    "# penalty=0.1\n",
    "# kreg=0\n",
    "# results = []\n",
    "# all_predict_sets_list=[]\n",
    "# for alpha in alphas:\n",
    "# #     for weight in saps_weights:\n",
    "# #         for penalty in raps_penalties:\n",
    "# #             for kreg in raps_kregs:\n",
    "#                 score_functions = [THR(), APS(), SAPS(weight=weight), RAPS(penalty=penalty, kreg=kreg)]\n",
    "#                 predictors = [SplitPredictor, ClusterPredictor, ClassWisePredictor]\n",
    "\n",
    "#                 for score_function in score_functions:\n",
    "#                     for Predictor in predictors:\n",
    "#                         predictor = Predictor(score_function=score_function, model=model)\n",
    "#                         predictor.calibrate(train_dataloader, alpha=alpha)\n",
    "\n",
    "#                         all_predict_sets = []\n",
    "#                         for batch in test_dataloader:\n",
    "#                             images, _ = batch\n",
    "#                             images = images.to(device)\n",
    "#                             predict_set = predictor.predict(images)\n",
    "#                             all_predict_sets.extend(predict_set)\n",
    "#                         all_predict_sets_list.append(all_predict_sets)\n",
    "#                         result_dict = predictor.evaluate(test_dataloader)\n",
    "\n",
    "#                         result_str = (f\"Dataset: {type(train_set).__name__}, \"\n",
    "#                                       f\"Score Function: {score_function.__class__.__name__}, \"\n",
    "#                                       f\"Predictor: {Predictor.__name__}, \"\n",
    "#                                       f\"Alpha: {alpha}, Weight: {weight if isinstance(score_function, SAPS) else 'N/A'}, \"\n",
    "#                                       f\"Penalty: {penalty if isinstance(score_function, RAPS) else 'N/A'}, \"\n",
    "#                                       f\"kreg: {kreg if isinstance(score_function, RAPS) else 'N/A'}, \"\n",
    "#                                       f\"Coverage Rate: {result_dict['Coverage_rate']}, \"\n",
    "#                                       f\"Average Size: {result_dict['Average_size']}\")\n",
    "#                         results.append(result_str)\n",
    "\n",
    "# # 打印或处理存储的结果\n",
    "# with open(f'12.27result_{log_name}.txt', 'a') as file:\n",
    "#     file.write(\"alpha loop\"+\"\\n\")\n",
    "# for result in results:\n",
    "#     #print(result)\n",
    "#     with open(f'12.27result_{log_name}.txt', 'a') as file:\n",
    "#         file.write(result+\"\\n\")\n",
    "# for all_predict_set in all_predict_sets_list:\n",
    "#     #print(all_predict_set)\n",
    "#     with open(f'12.27result_{log_name}.txt', 'a') as file:\n",
    "#         file.write(' '.join(all_predict_set)+\"\\n\")\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "# alpha=0.1\n",
    "# weight=1\n",
    "# penalty=0.1\n",
    "# kreg=0\n",
    "# results = []\n",
    "# all_predict_sets_list=[]\n",
    "# # for alpha in alphas:\n",
    "# #     for weight in saps_weights:\n",
    "# #         for penalty in raps_penalties:\n",
    "# for kreg in raps_kregs:\n",
    "#                 score_functions = [THR(), APS(), SAPS(weight=weight), RAPS(penalty=penalty, kreg=kreg)]\n",
    "#                 predictors = [SplitPredictor, ClusterPredictor, ClassWisePredictor]\n",
    "\n",
    "#                 for score_function in score_functions:\n",
    "#                     for Predictor in predictors:\n",
    "#                         predictor = Predictor(score_function=score_function, model=model)\n",
    "#                         predictor.calibrate(train_dataloader, alpha=alpha)\n",
    "\n",
    "#                         all_predict_sets = []\n",
    "#                         for batch in test_dataloader:\n",
    "#                             images, _ = batch\n",
    "#                             images = images.to(device)\n",
    "#                             predict_set = predictor.predict(images)\n",
    "#                             all_predict_sets.extend(predict_set)\n",
    "#                         all_predict_sets_list.append(all_predict_sets)\n",
    "#                         result_dict = predictor.evaluate(test_dataloader)\n",
    "\n",
    "#                         result_str = (f\"Dataset: {type(train_set).__name__}, \"\n",
    "#                                       f\"Score Function: {score_function.__class__.__name__}, \"\n",
    "#                                       f\"Predictor: {Predictor.__name__}, \"\n",
    "#                                       f\"Alpha: {alpha}, Weight: {weight if isinstance(score_function, SAPS) else 'N/A'}, \"\n",
    "#                                       f\"Penalty: {penalty if isinstance(score_function, RAPS) else 'N/A'}, \"\n",
    "#                                       f\"kreg: {kreg if isinstance(score_function, RAPS) else 'N/A'}, \"\n",
    "#                                       f\"Coverage Rate: {result_dict['Coverage_rate']}, \"\n",
    "#                                       f\"Average Size: {result_dict['Average_size']}\")\n",
    "#                         results.append(result_str)\n",
    "\n",
    "# # 打印或处理存储的结果\n",
    "# with open(f'12.27result_{log_name}.txt', 'a') as file:\n",
    "#     file.write(\"kreg loop\"+\"\\n\")\n",
    "# for result in results:\n",
    "#     #print(result)\n",
    "#     with open(f'12.27result_{log_name}.txt', 'a') as file:\n",
    "#         file.write(result+\"\\n\")\n",
    "# for all_predict_set in all_predict_sets_list:\n",
    "#     #print(all_predict_set)\n",
    "#     with open(f'12.27result_{log_name}.txt', 'a') as file:\n",
    "#         file.write(' '.join(all_predict_set)+\"\\n\")\n",
    "\n",
    "\n",
    "# alpha=0.1\n",
    "# weight=1\n",
    "# penalty=0.1\n",
    "# kreg=0\n",
    "# results = []\n",
    "# all_predict_sets_list=[]\n",
    "# # for alpha in alphas:\n",
    "# for weight in saps_weights:\n",
    "# #         for penalty in raps_penalties:\n",
    "# #             for kreg in raps_kregs:\n",
    "#                 score_functions = [THR(), APS(), SAPS(weight=weight), RAPS(penalty=penalty, kreg=kreg)]\n",
    "#                 predictors = [SplitPredictor, ClusterPredictor, ClassWisePredictor]\n",
    "\n",
    "#                 for score_function in score_functions:\n",
    "#                     for Predictor in predictors:\n",
    "#                         predictor = Predictor(score_function=score_function, model=model)\n",
    "#                         predictor.calibrate(train_dataloader, alpha=alpha)\n",
    "\n",
    "#                         all_predict_sets = []\n",
    "#                         for batch in test_dataloader:\n",
    "#                             images, _ = batch\n",
    "#                             images = images.to(device)\n",
    "#                             predict_set = predictor.predict(images)\n",
    "#                             all_predict_sets.extend(predict_set)\n",
    "#                         all_predict_sets_list.append(all_predict_sets)\n",
    "#                         result_dict = predictor.evaluate(test_dataloader)\n",
    "\n",
    "#                         result_str = (f\"Dataset: {type(train_set).__name__}, \"\n",
    "#                                       f\"Score Function: {score_function.__class__.__name__}, \"\n",
    "#                                       f\"Predictor: {Predictor.__name__}, \"\n",
    "#                                       f\"Alpha: {alpha}, Weight: {weight if isinstance(score_function, SAPS) else 'N/A'}, \"\n",
    "#                                       f\"Penalty: {penalty if isinstance(score_function, RAPS) else 'N/A'}, \"\n",
    "#                                       f\"kreg: {kreg if isinstance(score_function, RAPS) else 'N/A'}, \"\n",
    "#                                       f\"Coverage Rate: {result_dict['Coverage_rate']}, \"\n",
    "#                                       f\"Average Size: {result_dict['Average_size']}\")\n",
    "#                         results.append(result_str)\n",
    "\n",
    "# # 打印或处理存储的结果\n",
    "# with open(f'12.27result_{log_name}.txt', 'a') as file:\n",
    "#     file.write(\"weight loop\"+\"\\n\")\n",
    "# for result in results:\n",
    "#     #print(result)\n",
    "#     with open(f'12.27result_{log_name}.txt', 'a') as file:\n",
    "#         file.write(result+\"\\n\")\n",
    "# for all_predict_set in all_predict_sets_list:\n",
    "#     #print(all_predict_set)\n",
    "#     with open(f'12.27result_{log_name}.txt', 'a') as file:\n",
    "#         file.write(' '.join(all_predict_set)+\"\\n\")\n",
    "        \n",
    "        \n",
    "\n",
    "# alpha=0.1\n",
    "# weight=1\n",
    "# penalty=0.1\n",
    "# kreg=0\n",
    "# results = []\n",
    "# all_predict_sets_list=[]\n",
    "# # for alpha in alphas:\n",
    "# #     for weight in saps_weights:\n",
    "# for penalty in raps_penalties:\n",
    "# #             for kreg in raps_kregs:\n",
    "#                 score_functions = [THR(), APS(), SAPS(weight=weight), RAPS(penalty=penalty, kreg=kreg)]\n",
    "#                 predictors = [SplitPredictor, ClusterPredictor, ClassWisePredictor]\n",
    "\n",
    "#                 for score_function in score_functions:\n",
    "#                     for Predictor in predictors:\n",
    "#                         predictor = Predictor(score_function=score_function, model=model)\n",
    "#                         predictor.calibrate(train_dataloader, alpha=alpha)\n",
    "\n",
    "#                         all_predict_sets = []\n",
    "#                         for batch in test_dataloader:\n",
    "#                             images, _ = batch\n",
    "#                             images = images.to(device)\n",
    "#                             predict_set = predictor.predict(images)\n",
    "#                             all_predict_sets.extend(predict_set)\n",
    "#                         all_predict_sets_list.append(all_predict_sets)\n",
    "#                         result_dict = predictor.evaluate(test_dataloader)\n",
    "\n",
    "#                         result_str = (f\"Dataset: {type(train_set).__name__}, \"\n",
    "#                                       f\"Score Function: {score_function.__class__.__name__}, \"\n",
    "#                                       f\"Predictor: {Predictor.__name__}, \"\n",
    "#                                       f\"Alpha: {alpha}, Weight: {weight if isinstance(score_function, SAPS) else 'N/A'}, \"\n",
    "#                                       f\"Penalty: {penalty if isinstance(score_function, RAPS) else 'N/A'}, \"\n",
    "#                                       f\"kreg: {kreg if isinstance(score_function, RAPS) else 'N/A'}, \"\n",
    "#                                       f\"Coverage Rate: {result_dict['Coverage_rate']}, \"\n",
    "#                                       f\"Average Size: {result_dict['Average_size']}\")\n",
    "#                         results.append(result_str)\n",
    "\n",
    "# # 打印或处理存储的结果\n",
    "# with open(f'12.27result_{log_name}.txt', 'a') as file:\n",
    "#     file.write(\"penalty loop\"+\"\\n\")\n",
    "# for result in results:\n",
    "#     #print(result)\n",
    "#     with open(f'12.27result_{log_name}.txt', 'a') as file:\n",
    "#         file.write(result+\"\\n\")\n",
    "# for all_predict_set in all_predict_sets_list:\n",
    "#     #print(all_predict_set)\n",
    "#     with open(f'12.27result_{log_name}.txt', 'a') as file:\n",
    "#         file.write(' '.join(all_predict_set)+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-13T05:29:20.748297Z",
     "iopub.status.busy": "2024-01-13T05:29:20.748142Z",
     "iopub.status.idle": "2024-01-13T05:29:22.450104Z",
     "shell.execute_reply": "2024-01-13T05:29:22.449556Z",
     "shell.execute_reply.started": "2024-01-13T05:29:20.748280Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: torchcp in /usr/local/lib/python3.8/site-packages (0.1.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install torchcp\n",
    "from torchcp.classification.scores import THR, APS, SAPS, RAPS\n",
    "from torchcp.classification.predictors import SplitPredictor, ClusterPredictor, ClassWisePredictor\n",
    "\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-13T05:29:22.450966Z",
     "iopub.status.busy": "2024-01-13T05:29:22.450807Z",
     "iopub.status.idle": "2024-01-13T05:29:22.456928Z",
     "shell.execute_reply": "2024-01-13T05:29:22.456533Z",
     "shell.execute_reply.started": "2024-01-13T05:29:22.450947Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_and_log_results(model, alphas, weights, penalties, kregs, train_dataloader, test_dataloader, device, log_name):\n",
    "    results = []\n",
    "    all_predict_sets_list = []\n",
    "\n",
    "    for alpha in alphas:\n",
    "        for weight in weights:\n",
    "            for penalty in penalties:\n",
    "                for kreg in kregs:\n",
    "                    score_functions = [THR(), APS(), SAPS(weight=weight), RAPS(penalty=penalty, kreg=kreg)]\n",
    "                    predictors = [SplitPredictor, ClusterPredictor, ClassWisePredictor]\n",
    "\n",
    "                    for score_function in score_functions:\n",
    "                        for Predictor in predictors:\n",
    "                            predictor = Predictor(score_function=score_function, model=model)\n",
    "                            predictor.calibrate(train_dataloader, alpha=alpha)\n",
    "\n",
    "                            all_predict_sets = []\n",
    "                            for batch in test_dataloader:\n",
    "                                images, _ = batch\n",
    "                                images = images.to(device)\n",
    "                                predict_set = predictor.predict(images)\n",
    "                                all_predict_sets.extend(predict_set)\n",
    "                            all_predict_sets_list.append(all_predict_sets)\n",
    "                            result_dict = predictor.evaluate(test_dataloader)\n",
    "\n",
    "                            result_str = (f\"Dataset: {type(train_set).__name__}, \"\n",
    "                                          f\"Score Function: {score_function.__class__.__name__}, \"\n",
    "                                          f\"Predictor: {Predictor.__name__}, \"\n",
    "                                          f\"Alpha: {alpha}, Weight: {weight if isinstance(score_function, SAPS) else 'N/A'}, \"\n",
    "                                          f\"Penalty: {penalty if isinstance(score_function, RAPS) else 'N/A'}, \"\n",
    "                                          f\"kreg: {kreg if isinstance(score_function, RAPS) else 'N/A'}, \"\n",
    "                                          f\"Coverage Rate: {result_dict['Coverage_rate']}, \"\n",
    "                                          f\"Average Size: {result_dict['Average_size']}\")\n",
    "                            results.append(result_str)\n",
    "\n",
    "    # Write results to file\n",
    "    with open(f'{log_name}_results_new.txt', 'a') as file:\n",
    "        for result in results:\n",
    "            file.write(\"***************\")\n",
    "            file.write(result + \"\\n\")\n",
    "        # for all_predict_set in all_predict_sets_list:\n",
    "        #     predict_set_str = [' '.join(map(str, sublist)) for sublist in all_predict_set]\n",
    "        #     file.write('\\n'.join(predict_set_str) + \"\\n\")\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-13T05:29:22.457611Z",
     "iopub.status.busy": "2024-01-13T05:29:22.457466Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "log_name=\"CIFAR100\"\n",
    "model=torch.load(\"CIFAR100model\")\n",
    "alphas = [0.05, 0.1, 0.15, 0.2]\n",
    "saps_weights = [0.5, 1, 1.5, 2]\n",
    "raps_penalties = [0.05, 0.1, 0.15, 0.2]\n",
    "raps_kregs = [0, 1, 2, 5]\n",
    "\n",
    "evaluate_and_log_results(model, [0.1], [1], [0.1], raps_kregs, train_dataloader, test_dataloader, device, log_name)\n",
    "evaluate_and_log_results(model, [0.1], [1], raps_penalties, [0], train_dataloader, test_dataloader, device, log_name)\n",
    "evaluate_and_log_results(model, [0.1], saps_weights, [0.1], [0], train_dataloader, test_dataloader, device, log_name)\n",
    "evaluate_and_log_results(model, alphas, [1], [0.1], [0], train_dataloader, test_dataloader, device, log_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#torch.save(model,\"CIFAR100model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in np.array(training_acc):\n",
    "#     print(f\"{i:.5f}\",end=',')\n",
    "# print(\"\\n\\n\")\n",
    "# for i in np.array(testing_acc):\n",
    "#     print(f\"{i:.5f}\",end=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots()\n",
    "# epochs = list(range(1, 301))\n",
    "# line1 = ax.plot(epochs, np.array(training_acc), label=\"train acc\")\n",
    "# line2 = ax.plot(epochs, np.array(testing_acc), label=\"test acc\")\n",
    "# ax.set_xlabel('epochs')\n",
    "# ax.set_ylabel('accuracy')\n",
    "# ax.grid(True)\n",
    "# ax.set_ylim(0, 1)\n",
    "# ax.legend()\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
